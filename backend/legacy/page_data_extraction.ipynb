{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OPENAI_API_KEY is not set in .env file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m openai_api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY is not set in .env file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m llm = LlamaOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m, api_key=openai_api_key)\n\u001b[32m     22\u001b[39m Settings.llm = llm\n",
      "\u001b[31mValueError\u001b[39m: OPENAI_API_KEY is not set in .env file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI as OpenAIClient\n",
    "from dotenv import load_dotenv\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI as LlamaOpenAI\n",
    "\n",
    "import os\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in .env file\")\n",
    "\n",
    "llm = LlamaOpenAI(model=\"gpt-4o\", api_key=openai_api_key)\n",
    "Settings.llm = llm\n",
    "openai_client = OpenAIClient(api_key=openai_api_key)\n",
    "\n",
    "llama_cloud_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if not llama_cloud_api_key:\n",
    "    raise ValueError(\"LLAMA_CLOUD_API_KEY is not set in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f5ba448b-50cd-486c-ad1f-ee21a0ce1c63\n"
     ]
    }
   ],
   "source": [
    "llama_parser = LlamaParse(page_prefix=\"START OF PAGE: {pageNumber}\\n\",page_suffix=\"\\nEND OF PAGE: {pageNumber}\",api_key=\"\",verbose=True,result_type=\"markdown\")\n",
    "# Load the document again with the new parser settings\n",
    "file_name = \"sample_runbook.docx\"\n",
    "extra_info = {\"file_name\": file_name, \"file_type\": \"docx\"}\n",
    "\n",
    "documents = llama_parser.load_data(\"./runbooks/sample_runbook.docx\", extra_info=extra_info)\n",
    "for i, doc in enumerate(documents, start=1):\n",
    "    doc.metadata[\"page_number\"] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Full Markdown Content of Document ---\")\n",
    "print(documents[0].text[:500].strip() + \"...\\n\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 512, 128]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, ?it/s]\n",
      "1it [00:00, ?it/s]\n",
      "1it [00:00, 986.20it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "3it [00:00, ?it/s]\n",
      "4it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes parsed: 46\n",
      "\n",
      "\n",
      "Found 15 relevant nodes based on keywords.\n",
      "==================================================\n",
      "--- Relevant Node 1 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 2\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 2}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 2 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 3\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 3, 'col_schema': 'Column: Application\\nType: string\\nSummary: Names of different applications or systems.\\n\\nColumn: Production IP\\nType: string\\nSummary: IP addresses used in the production environment.\\n\\nColumn: DR IP\\nType: string\\nSummary: IP addresses used in the disaster recovery environment.'}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 3 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 3\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 3, 'table_df': \"{' Application       ': {0: ' Web Server        ', 1: ' App Server        ', 2: ' Payment Gateway   ', 3: ' Core Banking      ', 4: ' CRM               ', 5: ' HRMS              ', 6: ' Email Server      ', 7: ' File Server       ', 8: ' Monitoring System ', 9: ' Backup System     ', 10: ' Firewall          '}, ' Production IP ': {0: ' 192.168.9.10  ', 1: ' 192.168.9.20  ', 2: ' 192.168.9.30  ', 3: ' 192.168.9.40  ', 4: ' 192.168.9.50  ', 5: ' 192.168.9.60  ', 6: ' 192.168.9.70  ', 7: ' 192.168.9.80  ', 8: ' 192.168.9.90  ', 9: ' 192.168.9.100 ', 10: ' 192.168.9.110 '}, ' DR IP        ': {0: ' 10.10.10.10  ', 1: ' 10.10.10.20  ', 2: ' 10.10.10.30  ', 3: ' 10.10.10.40  ', 4: ' 10.10.10.50  ', 5: ' 10.10.10.60  ', 6: ' 10.10.10.70  ', 7: ' 10.10.10.80  ', 8: ' 10.10.10.90  ', 9: ' 10.10.10.100 ', 10: ' 10.10.10.110 '}}\", 'table_summary': 'This table lists various applications and their corresponding IP addresses for both production and disaster recovery (DR) environments. It serves as a quick reference for network configurations related to these applications.,\\nwith the following table title:\\nApplication IP Address Mapping,\\nwith the following columns:\\n- Application: Names of different applications or systems.\\n- Production IP: IP addresses used in the production environment.\\n- DR IP: IP addresses used in the disaster recovery environment.\\n'}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 4 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 3\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 3}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 5 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 4\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 4}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 6 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 5\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 5}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 7 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 6\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 6}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 8 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 7\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 7}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 9 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 8\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 8}\n",
      "-------------------------\n",
      "\n",
      "--- Relevant Node 10 ---\n",
      "Document Name: sample_runbook.docx\n",
      "Section: N/A (Top Level)\n",
      "Page Number: 9\n",
      "Original Metadata Dict: {'file_name': 'sample_runbook.docx', 'file_type': 'docx', 'page_number': 9}\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "print(f\"Total number of nodes parsed: {len(nodes)}\\n\")\n",
    "\n",
    "\n",
    "all_nodes_dict = {node.node_id: node for node in nodes}\n",
    "\n",
    "\n",
    "relevant_nodes = []\n",
    "keywords = [\"DR\", \"disaster\", \"recovery\", \"failover\", \"fallback\", \"redundant\"]\n",
    "\n",
    "for node in leaf_nodes:\n",
    "    if any(kw.lower() in node.text.lower() for kw in keywords):\n",
    "        relevant_nodes.append(node)\n",
    "\n",
    "print(f\"\\nFound {len(relevant_nodes)} relevant nodes based on keywords.\\n\" + \"=\"*50)\n",
    "\n",
    "\n",
    "for i, node in enumerate(relevant_nodes, start=1):\n",
    "    if i<=10:\n",
    "        print(f\"--- Relevant Node {i} ---\")\n",
    "        # print(f\"Text Snippet: {node.text[:100].strip()}...\")\n",
    "\n",
    "        doc_name = node.metadata.get('file_name', 'N/A')\n",
    "        print(f\"Document Name: {doc_name}\")\n",
    "\n",
    "        section_name = \"N/A (Top Level)\"\n",
    "        if node.parent_node:\n",
    "            parent_id = node.parent_node.node_id\n",
    "            \n",
    "            parent_node_obj = all_nodes_dict.get(parent_id)\n",
    "            \n",
    "            if parent_node_obj:\n",
    "                section_name = parent_node_obj.text.strip()\n",
    "                \n",
    "        print(f\"Section: {section_name}\")\n",
    "\n",
    "\n",
    "        page_num = node.metadata.get('page_number', 'N/A (Not available for .docx)')\n",
    "        print(f\"Page Number: {page_num}\")\n",
    "        \n",
    "        print(f\"Original Metadata Dict: {node.metadata}\")\n",
    "        print(\"-\" * 25 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
